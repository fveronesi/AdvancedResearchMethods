---
title: "Advanced Research Methods - E7004"
subtitle: "Day 1 - Introduction"
author: "Dr. Fabio Veronesi"
date: "5 March 2018"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=F)
```

##**Summary**
- Introduction
- Data Structures
- Data types
- Subsetting
- Importing Data
- Descriptive Statistics
- Plotting

***
####*NOTE*
This document has been written using R Markdown syntax. This way when we click `Ctrl+Shift+K` we can compile a professional looking report of what we've covered today.

More info on R Markdown syntax at:

[basic-writing-and-formatting-syntax](https://help.github.com/articles/basic-writing-and-formatting-syntax)

[Markdown-Here-Cheatsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Here-Cheatsheet#lists)

[rmarkdown-cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf)

[rmarkdown-reference](https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf)

***

##**Introduction**
R is a powerful object-oriented programming language specifically designed for statistics. Object-oriented means that we can assign data to named objects and use them for computations.

It is free and open-source and can be downloaded for free at:
[CRAN](https://cran.r-project.org/)

I also suggest to download R Studio, which makes writing code much easier:
[R-Studio](https://www.rstudio.com/)

***

##**Data Structures**
More info on data structures here:
[venus.ifca.unican.es](http://venus.ifca.unican.es/Rintro/dataStruct.html)

The most important data structures are vector, matrix, data.frame and lists (array is not used much)
![Source: venus.ifca.unican.es](http://venus.ifca.unican.es/Rintro/_images/dataStructuresNew.png)


###**Vectors**
Vectors are simply 1D arrays of any type, e.g. numerical, categorical or strings.
```{r}
A = rnorm(n=20, mean=4, sd=1)

A
```

A is a vector with 40 elements. We created this vector by using the function `rnorm`, which randomly samples n = 20 numerical values from a normal distribution (mean = 4, sd = 1)


```{r}
length(A)
```

We can obtain the length, i.e. the number of elements, in the vector using the function length. A is an object, specifically a 1D array also referred to as vector in R, and it can be used as such for analyses.


```{r}
B = A + 3

B
```

This expression adds 3 to each element of the vector, and stores this new vector into an object named B.

###**Matrix**
Data can also be stored into more complex objects, like matrix and data.frame:


```{r}
M = matrix(1:40, nrow=8, ncol=5)
```

This line creates a 8x5 matrix, which is a 2D object with a total of 40 elements.

We can look at it using the function print


```{r}
print(M)
```

Please notice the way R fills the matrix. It does so by column.

We can change that using the option `byrow`:


```{r}
M = matrix(1:40, nrow=8, ncol=5, byrow=T)
print(M)
```

The function help can be very useful when we are not familiar with a function

`help(matrix)`   


###**Data.Frame**
Other important objects are data.frame

```{r}
head(iris)
```

`iris` is one of the numerous datasets freely available in R that we can use for testing. The function `head` allows us to just look at the first few rows of the dataset.

As you can see this object has multiple columns and many rows, but the entries are not only numeric.

```{r}
str(iris)
```


The function `str` allows us to visualize the structure of any object, and it is particularly useful for data.frame. It tells us that this dataset has 150 observations (rows) and 5 variables (columns). It also tell us that the first 4 variables are numerical (`num`), while the last is categorical (or factorial).

Other types of variables could be logical (e.g. TRUE or FALSE), or strings (e.g. "TEST")


###**List**
The last data type we are going to look at are lists. These allow to store diverse data types:


```{r}
L = list(A, M)
print(L)
```



This list has two elements, the first is a vector while the second is a matrix.

***
##**Subsetting**
We can use square brackets to extract elements from all data types. However, the syntax changes between objects.

Vector are 1D arrays so we can extract elements just by specifying the position along the vector we want to extract, starting from 1 up to length(vector)


```{r}
A[1]
```

This extract the first element of the vector:


```{r}
A[length(A)]
```

This extracts the last element, in position equal to length(A), which is 40.

For matrix and data.frame, since these are 2D objects, we need to specify both a row and a column to extract:

```{r}
M[3,5]

iris[4,4]
```



We can also extract multiple elements

```{r}
iris[1:4, 2]
```


This line extract from row 1 to row 4, but only elements in column 2

We can also extract entire rows or columns

For example: 

```{r}
M[1,]
```


Extract the whole row 1

While:

```{r}
M[,3]
```

Extracts the whole column 3

In a data.frame we can also extract columns by name

```{r}
iris$Sepal.Length
```


For lists, since they are complex objects, we have two levels of extraction

```{r}
L[[1]]
```


The first levels, identified by 2 square brackets, extract the element of the list 9in this case element 1, which is a vector)
Then we can extract a particular element from the vector adding an additional level

L[[1]][1]

The same would be true for the second element, which is a data.frame

```{r}
L[[2]][3,5]
```



***
##**Importing Data**
In this course we will use data freely available on-line
These can be downloaded from: [sheffield.ac.uk](https://www.sheffield.ac.uk/mash/statistics2/data)
A short description is also available

First of all we need to specify our working directory so that R knows where to load and save data
We can do that via the function `setwd`

```{r, eval=F}
setwd("J:/Teaching_Harper/Advanced Research Methods - E7004/Possible Datasets")
```

Please notice the forward slash (`/`) instead of the back slash we normally use


Another way is go to Session->Set Working Directory directly in R Studio

Now we can import our data. The easiest way to import tables from csv files, which we could also do directly from the web:

```{r}
Crimes = read.csv("https://www.sheffield.ac.uk/polopoly_fs/1.569434!/file/stcp-Rdataset-Crime.csv")

str(Crimes)
```


Please notice the name of the first variable `ï..CrimeRate`. This sometimes happens with R, which probably has some issues with this particular file.
It is important to notice this, because we always need to use accurate variable names in R, otherwise the script will not work.

We can find the description of the dataset at this link:

[Crime_data_summary](https://www.sheffield.ac.uk/polopoly_fs/1.547014!/file/Crime_data_summary.docx)



Even though reading csv is the easiest way to import data, there are many other types of data that can be imported into R (e.g. Excel sheet). To find out more on how to import different types of data please look at the links below:

[Quick-R](https://www.statmethods.net/input/importingdata.html)

[DataCamp](https://www.datacamp.com/community/tutorials/r-data-import-tutorial)




***
##**Descriptive Statistics**
Descriptive statistics is a basic technique that is used to describe a dataset.  
This technique relies on indexes to capture important features of the dataset, like mean and standard deviation, which will help us to compare it with other data

###**Centrality**
The most popular index of centrality is the mean, or arithmetic average:

###$\displaystyle\bar{y} = \frac{1}{n} \times \sum_{i=1}^{n} y_i$

where $\bar{y}$ is the mean of a variable $y$, $n$ is the number of elements in $y$. The mean is simply the sum of all $Y_i$ from 1 to $n$.

We can compute the mean for example of the variable CrimeRate
```{r}
mean(Crimes$ï..CrimeRate)
```


Another useful measure of centrality is the median, which is defined as the middle value of a series of numbers, listed in numerical order.
We can simply compute it using the function `median` in R:

```{r}
median(Crimes$ï..CrimeRate)
```


###**Spread**
The Variance is a measure of spread and indicates the average amount of dispersion, i.e. distance, from the mean of each value in a dataset.
It can be simply computed as follows:

####$\displaystyle s^2 = \frac{1}{n-1} \times \sum_{i=1}^{n} {(y_i - \bar{y})}^2$

By definition, the variance is sum of the square differences between each observation $y_i$ and the mean $\bar{y}$, divided by the number of observations minus 1.

***
####_Note_
The previous equation was written using the Latex syntax.
More info here: [Latex Equation Reference](https://en.wikibooks.org/wiki/LaTeX/Mathematics#Powers_and_indices)

***

In R, the variance can be simply computed as follows:
```{r}
var(Crimes$ï..CrimeRate)
```


The Standard Deviation ($s$) is the square root of the variance:
```{r}
sd(Crimes$ï..CrimeRate)
```


###**Summary**
Sometimes, instead of computing indexes for single variable we are more interested in looking at the whole dataset at once.

We can do that with the function `summary`:
summary(Crimes)

This function returns several important information for all the variables in the data.frame `Crimes`. 

Beside, mean and median it also reports the minimum and maximum values, and the first and third quartiles, which are useful to understand the shape of the distribution.

###**Quantiles**
Quantiles are just cut points that the probability distribution of our data into equal probability intervals.

![Source: mathspace.co](https://mathspace-production-media.mathspace.co/media/upload/images/11-Normal-Distribution/78th_percentile2.png)

In this example, the $78^{th}$ percentile is the point below which $78%$ of observations lie. 

Important for statistics is the division of the distribution into four parts, in this case we talk about quartiles.

Quartiles are important because they allow to measure spread in case when our distribution is not normal: using the distance between first and third quartiles.

![Source: wikipedia](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Boxplot_vs_PDF.svg/598px-Boxplot_vs_PDF.svg.png)

The interquartile range can be easily computed in R with the function `IQR`:

```{r}
IQR(Crimes$ï..CrimeRate)
```



***
##**Plotting**
The final part of this lecture is dedicated to plotting.

Plots are extremely important because they allow us to graphically represent our data and doing so can really help us understanding what is going on within our dataset.

There are many useful plots that we will use throughout the course. In particular we will look at histograms and box-plots, which allows us to visualise and compare distributions; bar-charts, which are useful to develop hypothesis particularly for categorical data; and scatterplots, which are very useful to understand the relation between variables.

###**Histograms**
Histograms are plots designed to represent distributions. To create a histogram we simply need to divide our data into non-overlapping "bins", meaning small intervals, which will be plotted on the X axis. Then we count the number of values that fall into each bin, and this number is plotted on the Y axis.

Let's look at an example, again using the `ï..CrimeRate` variable:
```{r}
hist(Crimes$ï..CrimeRate)
```


As you can see the histogram has split the data into 7 bins, and plot the frequency (i.e. the number of values within each bin) on the Y axis.

We can embellish this plots a bit by changing title and the label on the X axis, with the options `main` and `xlab`:
```{r}
hist(Crimes$ï..CrimeRate, main="Histogram Crime Rates", xlab="Crime rate (number of offences per million population)")
```


As mentioned, histograms are very useful to check the shape of the distribution. For example, in this case we can see that the distribution is very similar to a normal distribution, with its typical bell shape. This is extremely useful particular when we will start looking at statistical tests. In fact, many tests are specifically designed to deal only with normally distributed data.

###**Bar Charts**
Bar charts are very useful when we need to compare groups. In the dataset Crimes there are variables that are binary, i.e. either 0 or 1. For example, Southern reports whether crimes were reported from Southern states or not; let's say we want to compare averages of crimes from Southern and Northern countries. For this task bar charts are the right tools.

Before we can plot the data we need to compute averages for both categories in the variable Southern. We can do it with the function `tapply`: 

```{r}
Mean = tapply(X=Crimes$ï..CrimeRate, INDEX=Crimes$Southern, FUN=mean)
Mean
```


The function `tapply`, applies a function (`FUN`) to a continuous variable (`X`), divided by groups (`INDEX`).

Once we have the mean we can plot the bars using `barplot`:

```{r}
barplot(Mean, names.arg=c("Northern States", "Southern States"))
```


It seems, that Northern states have slightly more crimes. 

We can provide more details on the plot by creating error bars: for example using the standard error of the mean.
Standard error is computed as follows:

###$\displaystyle SEM = \frac{s}{\sqrt{n}}$

where $s$ is the standard deviation, and $n$ is the number of samples.

In base R there is nor function to compute the standard error, but we can create one:

```{r}
SEM = function(x){sd(x) / sqrt(length(x))}
```


This simple function will accept a vector, `x`, as only input. Then it will compute the standard error as a ratio between the standard deviation, `sd`, and the square root, `sqrt`, of the number of elements, `length`, of the vector `x`.
Now that we have a function we can again use `tapply`, to compute standard errors for each category:
```{r}
SEM.STATES = tapply(X=Crimes$ï..CrimeRate, INDEX=Crimes$Southern, FUN=SEM)
SEM.STATES
```


Now, we can add the error bars to the plot, with `segments` and `arrows`. However, first we need to recall the plot and save it into an object:

```{r}
BC_PLOT = barplot(Mean, names.arg=c("Northern States", "Southern States"), ylim=c(0,120))
```


The object `BC_PLOT` now contain the plot, and in particular the coordinates of the two bars. We also added the option `ylim`, to manually set the range of Y to plot. This way we can make sure the error bars are fully visible. 
```{r}
BC_PLOT
```


With these number we can specify where to insert the error bars, as twice the standard error of the mean:
```{r}
BC_PLOT = barplot(Mean, names.arg=c("Northern States", "Southern States"), ylim=c(0,120))

segments(BC_PLOT, Mean - (2*SEM.STATES), BC_PLOT, Mean + (2*SEM.STATES), lwd = 1.5)

arrows(BC_PLOT, Mean - (2*SEM.STATES), BC_PLOT, Mean + (2*SEM.STATES), lwd = 1.5, angle = 90, code = 3, length = 0.05)
```


To know more about the code in the last two function please refer to:
[www.r-bloggers.com/building-barplots-with-error-bars/](https://www.r-bloggers.com/building-barplots-with-error-bars/)

Plotting confidence intervals around the mean is extremely useful since it may provide good indications of statistical differences between them. If two error bars are overlapping there are good chances that with a formal test the two groups will not result statistically different. This is something we can use to formulate our hypothesis before applying any statistical test.


###**Scatterplot**
The last type of graph allows us to visualise the relation between two continuous variables. For example, let's say we want to visualise the relation between Crime rate and Wages, we can do that simply by:


```{r}
plot(ï..CrimeRate ~ Wage10, data=Crimes, pch=20, xlab="Median Weekly Wage", ylab="Crime rate")
```


It seems there is a positive correlation between the two, i.e. when one increases the other also increases.

This sort of plots are extremely useful in hypothesis testing, since it allows us to immediately figure out that some variable may be driving the pattern we see in our target variable, in this case Crime rates.


###**Box-Plots**
Box-Plots are another way to represent distributions, this time using quartiles. They are also very useful to compare distributions.

First of all, let's look at the R code to generate box-plots:
```{r}
boxplot(Crimes$ï..CrimeRate, main="Histogram Crime Rates", xlab="Crime rate (number of offences per million population)")
```


Box-plots are a clever way of representing distributions. They features a box, which ranges from the first (`Q1`) to the third quartile (`Q3`). Inside there is a black line that corresponds to the median. Then we have the two whiskers, which extend up to a distance of 1.5 time the interquartile range below Q1 and above Q3. Outside this range we sometimes see dots that are considered outliers.

The image below illustrates how to interpret box-plots:

![Source: lsc.studysixsigma.com](https://lsc.studysixsigma.com/wp-content/uploads/sites/6/2015/12/1435.png)

We can increase the amount of information displayed by adding a red dot on the mean value. This can be done with the function `points`:
```{r}
boxplot(Crimes$ï..CrimeRate, main="Histogram Crime Rates", xlab="Crime rate (number of offences per million population)")
points(mean(Crimes$ï..CrimeRate), pch=16, col="red")
```


As you can see the function `points` is written after the call to create the plot.

Moreover, within the call to `points` we have two more options: `pch` and `col`.

The first, `pch`, is used to change the symbol used for the dot and it can be any of the symbols below:

![pch symbols, source: isu.r-forge.r-project.org](http://isu.r-forge.r-project.org/vistat/2013-04-08-plotting-symbols-and-color-palettes/pch.png)

The option `col` is used to change the colour of the symbol, which by default is black. We can either write the colour: e.g. red, green, yellow.

Alternatively, we can select more advanced colours from the range below:

![Author: Earl F. Glynn (2005)](http://research.stowers.org/mcm/efg/R/Color/Chart/ColorsChart3.jpg)

Box plots are a very good way of comparing distributions of different groups. We can do that including a formula, for example specifying that we want to plot distributions of Crime Rate as a function of Youth unemployment:

```{r}
boxplot(Crimes$ï..CrimeRate  ~ Crimes$HighYouthUnemploy, main="Histogram Crime Rates", xlab="Crime rate (number of offences per million population)")
```

Box plots can be used with any distribution. However, their role become very important when we are dealing with non-normal data. In fact, with normal distribution we can simply use a bar-chart to plot the mean values of each group, and an error bar with the confidence interval (computed as twice the standard error of the mean). However, for data that do not fit a normal distribution this is not possible and this is where box plot become very useful. In fact, using the interquartile range (IQR) we can compute confidence intervals around the median, with the following equation:

####$CI_{Median} = Median \pm 1.57 \times \frac{IQR}{\sqrt{n}}$

Confidence intervals around the median can be plotted in R as notches, with the option `notch`:

```{r}
boxplot(Crimes$ï..CrimeRate  ~ Crimes$HighYouthUnemploy, notch=T, main="Histogram Crime Rates", xlab="Crime rate (number of offences per million population)")
```

The interpretation is very similar to the confidence intervals around the mean. Therefore if the two notches are overlapping there are good chances that with a formal test the two groups will not result statistically different.



***
##**Conclusions**
In this lecture we learned the basics of the R language, such as importing and subsetting data. We also started learning useful technique to explore our dataset, both in terms of descriptive indexes, and by visualising our variables.

In the next lecture, we will start covering some important topics like experimental designs and power analysis.



***
##**References**
Material to implement what we discuss during lectures can be downloaded on my OneDrive.

I also developed a video tutorial for Pack Publishing, which again students can download from OneDrive:

[OneDrive](https://goo.gl/Yfr1Y3)

***
##**Homework**
Homework are meant to help you during the learning process. They will not be marked and they are not mandatory.
However, if you have time and you want to do some additional work to better understand the R language these are some things you can try. Please save all your homework, from each day, into a single file: name_surname_StudentID.R

Please identify each day with specific comments. A comment in R can be included with the hash-tag (#):
```
#Comment: you can write whatever neccesary for me to understand your reasoning
```

At the end of the module you can then send the R file to me: fveronesi@harper-adams.ac.uk

You can find the list of homework below:

1. From this [page](https://www.sheffield.ac.uk/mash/statistics2/data), download the Diet dataset and place it in a folder of your choice. Then set the working directory pointing to the same folder where you downloaded the dataset. Finally load the dataset using `read.csv`.

2. Subset the dataset by gender (be careful for the NA values) and compute the mean values for the variable weight6weeks for both subsets.

3. Create a bar-chart using the two subsets.

4. Create a scatterplot between pre.weight and weight6weeks.

5. Comment the scatterplot and the relation between variables.
